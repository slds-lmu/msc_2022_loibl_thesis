\documentclass[9pt, xcolor=table]{beamer}

\usepackage[utf8]{inputenc}
\usepackage[round, comma]{natbib}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{verbatim}
\DeclareMathOperator*{\argmin}{arg\,min}



\mode<presentation> {

\usetheme{Madrid}

\setbeamertemplate{navigation symbols}{} 
\useinnertheme{circles}
\definecolor{greenish}{RGB}{0, 153, 76}
\usecolortheme[named=greenish]{structure}
}

\setbeamertemplate{headline}
{%
  \begin{beamercolorbox}[ht=3.5ex,dp=1.125ex,%
      leftskip=.3cm,rightskip=.3cm plus1fil]{section in head/foot}
    \usebeamerfont{section in head/foot}\usebeamercolor[fg]{section in head/foot}%
\insertsectionnavigationhorizontal{\paperwidth}{\hskip0pt plus1fill}{\hskip0pt plus1fill}
  \end{beamercolorbox}%
  \begin{beamercolorbox}[colsep=1.5pt]{middle separation line head}
  \end{beamercolorbox}
  \begin{beamercolorbox}[colsep=1.5pt]{lower separation line head}
  \end{beamercolorbox}
}

\title[Interpretation of black box models]{Interpretation of black box models using tree-based surrogate models \newline \small{Simulations}}
\author[Sofia Loibl]{Sofia Loibl}
\institute[LMU]{LMU MÃ¼nchen}
\date{\today}

\begin{document}

\begin{frame}
\titlepage 
\end{frame}


\begin{frame}
\frametitle{Outline} 
\tableofcontents 
\end{frame}


\section{Simulation basic Scenarios}
\begin{frame}{Simulation design}
Comparison of four MBT algorithms (SLIM, GUIDE, MOB, CTree)
with respect to performance, stability and interpretability.

\vspace{0.3cm}
\begin{itemize}
    \item 3 basic scenarios (linear smooth, linear abrupt, linear mixed)
    \item MBT as standalone (to measure accuracy of the MBT algorithms), surrogate for lm and surrogate for xgboost model (to measure fidelity)
    \item 3 different sample sizes (1000, 5000, 10000)
    \item 3 different pruning parameters (for alpha or impr)\end{itemize}
    
$\Rightarrow 3 \cdot 3 \cdot 3 \cdot 3 = 81$ Experiments for each MBT algorithm

\vspace{0.3cm}
100 Simulation runs

    
\end{frame}

\begin{frame}{Evaluation measures}
\begin{enumerate}
    \item Performance: $R^2$ and $MSE$ on training and test data
    \item Interpretability: number of leaf nodes
    \item Stability: Adjusted Rand Index (ARI)
\end{enumerate}
    
\end{frame}

\section{Linear Smooth}
\begin{frame}{Linear Smooth}
\textbf{Data}
\begin{itemize}
    \item $x_1,..., x_3 \sim U(-1,1)$ 
    \item $ f_{ls}(x) = x_1 + 4   x_2 + 3   x_2   x_3 $
    \item $\epsilon \sim N(0, 0.1 sd(f_{ls}(x))$
    \item $y = f_{ls}(x) + \epsilon$
\end{itemize}

\textbf{Settings:}
\begin{itemize}
    \item max tree depth = 7 
    \item min node size = 50    
\end{itemize}

\end{frame}

\begin{frame}{Linear Smooth}
\textbf{Comparison of MBTs as stand alone models}
\begin{table}
\caption{Mean simulation results on 100 simulation runs for \textbf{SLIM} and \textbf{GUIDE} as stand alone model on scenario Linear smooth with $n = 1000$ for different values of $impr$}
\centering \tiny
\begin{tabular}[t]{r|r|r|r|r|r|r|r|r}
\hline
MBT & impr & mean n leaves & n leaves min & n leaves max & mean R2 train & sd R2 train & mean R2 test & sd R2 test\\
\hline
SLIM & 0.15 & 2.27 & 2 & 5 & 0.9584 & 0.0072 & 0.9557 & 0.0076\\
\hline
SLIM & 0.10 & 10.09 & 5 & 15 & 0.9860 & 0.0057 & 0.9835 & 0.0059\\
\hline
SLIM & 0.05 & 14.75 & 12 & 18 & 0.9909 & 0.0006 & 0.9884 & 0.0009\\
\hline
GUIDE & 0.15 & 2.25 & 2 & 5 & 0.9582 & 0.0071 & 0.9555 & 0.0072\\
\hline
GUIDE & 0.10 & 9.81 & 5 & 14 & 0.9859 & 0.0058 & 0.9834 & 0.0060\\
\hline
GUIDE & 0.05 & 14.60 & 11 & 17 & 0.9907 & 0.0006 & 0.9883 & 0.0009\\
\hline
\end{tabular}
\end{table}

\begin{table}

\caption{Mean simulation results on 100 simulation runs for \textbf{SLIM} and \textbf{GUIDE} as stand alone model on scenario Linear smooth with $n = 1000$ for different values of $alpha$}
\centering \tiny
\begin{tabular}[t]{r|r|r|r|r|r|r|r|r}
\hline
MBT & alpha & mean n leaves & n leaves min & n leaves max & mean R2 train & sd R2 train & mean R2 test & sd R2 test\\
\hline
MOB & 0.001 & 9.48 & 8 & 13 & 0.9898 & 7e-04 & 0.9876 & 0.0011\\
\hline
MOB & 0.010 & 11.02 & 8 & 14 & 0.9902 & 7e-04 & 0.9879 & 0.0011\\
\hline
MOB & 0.050 & 12.54 & 9 & 15 & 0.9906 & 6e-04 & 0.9882 & 0.0010\\
\hline
CTree & 0.001 & 11.35 & 9 & 14 & 0.9900 & 6e-04 & 0.9881 & 0.0010\\
\hline
CTree & 0.010 & 12.74 & 10 & 15 & 0.9904 & 6e-04 & 0.9884 & 0.0010\\
\hline
CTree & 0.050 & 13.76 & 11 & 16 & 0.9905 & 6e-04 & 0.9885 & 0.0010\\
\hline
\end{tabular}
\end{table}

    
\end{frame}





\begin{frame}{Linear Smooth}
For  $alpha= 0.001$ and $impr = 0.1$ the mean number of leaf nodes nodes is similar for the four MBT Algorithms, although it varies greatly for SLIM and CTree
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_int.pdf}
\end{figure}   

    
\end{frame}

\begin{frame}{Linear Smooth}
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_r2_train.pdf}
\end{figure}  
    
\end{frame}

\begin{frame}{Linear Smooth}
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_sta.pdf}
\end{figure}  
    
\end{frame}

\begin{frame}{Linear Smooth}
\textbf{Observations:}
\begin{itemize}
    \item All four algorithms achieve good performance
    \item The number of leaf nodes is high considering that the data generating process is very simple and involves only one interaction (increases even more with larger n)    
    \item SLIM and GUIDE are very sensitive regarding the choice of impr
    \item  given the number of leave nodes is identical, MOB and GUIDE provide more stable MBTs and have a better performance.

\end{itemize}

\textbf{Suggestion:}\\
Select a smaller maximum tree depth and a larger min node size in order to avoid large fluctuations and to obtain trees that are easier to interpret.

    
\end{frame}

\begin{frame}{Linear Smooth - Interpretability}
Comparison of MBTs used as surrogate models on lm predictions vs. used as stand alone models 
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_lm_int.pdf}
\end{figure}  
\end{frame}

\begin{frame}{Linear Smooth - Performance}
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_lm_r2_train.pdf}
\end{figure}  
\end{frame}


\begin{frame}{Linear Smooth - Stability}

\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_smooth/ls_1000_standalone_lm_sta.pdf}
\end{figure}  
\end{frame}

\begin{frame}{Linear Abrupt}
\textbf{Data:}
\begin{itemize}
    \item $x_1, x_2 \sim U(-1,1)$, $x_3 \sim Bern(0.5)$
    \item $ f_{la}(x) = x_{1} - 8  x_2 + 16  x_2  \mathbf{I}_{x_3 = 0} + 8  x_2  \mathbf{I}_{x_1 > mean(x_1)}$
    \item $\epsilon \sim N(0, 0.1 sd(f_{la}(x))$
    \item $y = f_{la}(x) + \epsilon$
\end{itemize} 

\textbf{Settings:}
\begin{itemize}
    \item max tree depth = 7 
    \item min node size = 50    
\end{itemize}
\end{frame}


\begin{frame}{Linear Abrupt}
\textbf{Comparison of MBTs as stand alone models}

\begin{table}
\caption{Mean simulation results on 100 simulation runs for \textbf{SLIM} and \textbf{GUIDE}  as stand alone model on scenario Linear abrupt with n = 1000 for different values of impr }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
impr & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.15 & 2.01 & 0.8283 & 0.8255 & 0.9950\\
\hline
0.10 & 4.00 & 0.9889 & 0.9876 & 0.9742\\
\hline
0.05 & 4.00 & 0.9892 & 0.9878 & 0.9735\\
\hline
\end{tabular}
\end{table}    

Results of SLIM and GUIDE are identical in this special case
\end{frame}

\begin{frame}{Linear Abrupt}

\begin{table}

\caption{Mean simulation results on 100 simulation runs for \textbf{MOB} as stand alone model on scenario Linear abrupt with n = 1000 for different values of impr }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
alpha & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.001 & 12.83 & 0.9660 & 0.9554 & 0.5520\\
\hline
0.010 & 14.24 & 0.9736 & 0.9640 & 0.5544\\
\hline
0.050 & 14.84 & 0.9751 & 0.9660 & 0.5555\\
\hline
\end{tabular}
\end{table}  

\begin{table}

\caption{Mean simulation results on 100 simulation runs for \textbf{CTree} as stand alone model on scenario Linear abrupt with n = 1000 for different values of impr }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
alpha & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.001 & 11.96 & 0.9489 & 0.9384 & 0.6427\\
\hline
0.010 & 12.74 & 0.9501 & 0.9397 & 0.6316\\
\hline
0.050 & 13.59 & 0.9511 & 0.9409 & 0.6105\\
\hline
\end{tabular}
\end{table}

No configuration is included where the average number of leaf nodes matches between the MBTs.
\end{frame}

\section{Linear Abrupt}
\begin{frame}{Linear Abrupt - Interpretability}

\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_abrupt/la_1000_standalone_lm_int.pdf}
\end{figure}    
\begin{itemize}
    \item Despite the small value for impr, SLIM and GUIDE generate only very small trees on the original data 
    \item When SLIM and GUIDE are used as surrogates for a linear model, the number of leaf nodes increases and varies strongly (more pronounced with SLIM than with guide). However, it remains below the number of leaf nodes for MOB and CTree.
\end{itemize}
\end{frame}


\begin{frame}{Linear Abrupt - Performance}
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_abrupt/la_1000_standalone_lm_r2_train.pdf}
\end{figure}     
\begin{itemize}
    \item SLIM and GUIDE achieve better performance despite lower number of leaf nodes
    \item MOB has better performance than CTree (This could be due to the fact that abrupt splits are more difficult to detect with the linear test statistics in CTree \citep{Schlosser.2019})
\end{itemize}
\end{frame}

\begin{frame}{Linear Abrupt - Stability}
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_abrupt/la_1000_standalone_lm_sta.pdf}
\end{figure}     
\begin{itemize}
    \item With SLIM and GUIDE very high stability on the original data, poorer stability and large fluctuations when used as a surrogate
    \item For MOB and CTree, stability improves when used as surrogates
\end{itemize}
\end{frame}


\section{Linear Mixed}
\begin{frame}{Linear Mixed}
\textbf{Data}
\begin{itemize}
    \item $x_1,x_2 \sim U(-1,1)$  $x_3, x_4 \sim Bern(0.5)$
    \item $ f_{lm}(x) = 4 x_2 + 2 x_4 + 4 x_1 x_2 + 8 x_2 \mathbf{I}_{x_3 = 0} + 1 x_1 x_2 \mathbf{I}_{x_4 = 1}  $
    \item $\epsilon \sim N(0, 0.1 sd(f_{lm}(x))$
    \item $y = f_{lm}(x) + \epsilon$
\end{itemize}

\textbf{Settings:}
\begin{itemize}
    \item max tree depth = 7 
    \item min node size = 50    
\end{itemize}

\end{frame}   

\begin{frame}{Linear Mixed}
\begin{table}

\caption{Mean simulation results on 100 simulation runs for SLIM as stand alone model on scenario Linear Mixed with n = 1000 for different values of impr }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
impr & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.15 & 3.71 & 0.8878 & 0.8817 & 0.6649\\
\hline
0.10 & 12.66 & 0.9791 & 0.9733 & 0.4598\\
\hline
0.05 & 14.62 & 0.9827 & 0.9769 & 0.4715\\
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Mean simulation results on 100 simulation runs for GUIDE as stand alone model on scenario Linear Mixed with n = 1000 for different values of impr}
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
impr & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.15 & 3.52 & 0.8846 & 0.8789 & 0.6518\\
\hline
0.10 & 12.12 & 0.9769 & 0.9711 & 0.4573\\
\hline
0.05 & 14.28 & 0.9821 & 0.9768 & 0.4444\\
\hline
\end{tabular}
\end{table}
    
\end{frame}

\begin{frame}{Linear Mixed}
\begin{table}

\caption{Mean simulation results on 100 simulation runs for MOB as stand alone model on scenario Linear Mixed with n = 1000 for different values of alpha }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
alpha & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.001 & 14.43 & 0.9802 & 0.9730 & 0.5041\\
\hline
0.010 & 14.82 & 0.9803 & 0.9732 & 0.5152\\
\hline
0.050 & 14.85 & 0.9803 & 0.9727 & 0.4935\\
\hline
\end{tabular}
\end{table}

\begin{table}

\caption{Mean simulation results on 100 simulation runs for CTree as stand alone model on scenario Linear Mixed with n = 1000 for different values of impr }
\centering
\begin{tabular}[t]{r|r|r|r|r}
\hline
alpha & number of leaf nodes & R2 train & R2 test & ARI\\
\hline
0.001 & 14.85 & 0.9802 & 0.9732 & 0.5193\\
\hline
0.010 & 14.99 & 0.9802 & 0.9731 & 0.5134\\
\hline
0.050 & 14.95 & 0.9800 & 0.9726 & 0.5113\\
\hline
\end{tabular}
\end{table}
    
\end{frame}

\begin{frame}{Linear Mixed - Interpretability}
For  $alpha= 0.001$ and $impr = 0.05$ the mean number of leaf nodes nodes is similar for the four MBT Algorithms
\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_mixed/lm_1000_standalone_lm_int.pdf}
\end{figure}     
\end{frame}

\begin{frame}{Linear Mixed - Performance}

\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_mixed/lm_1000_standalone_lm_r2_train.pdf}
\end{figure}  
\begin{itemize}
    \item SLIM and GUIDE have a higher performance than MOB and CTree
    \item Fidelity is higher than accuracy, i.e. better performance on the lm predictions
\end{itemize}
\end{frame}

\begin{frame}{Linear Mixed - Performance}

\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_mixed/lm_1000_standalone_lm_r2_test.pdf}
\end{figure}  

\end{frame}

\begin{frame}{Linear Mixed - Stability}

\begin{figure}
    \includegraphics[width=11cm]{Figures/simulations/batchtools/basic_scenarios/linear_mixed/lm_1000_standalone_lm_sta.pdf}
\end{figure}     
\begin{itemize}
    \item Here stability is higher if the MBTs are used as surrogates (as stated in the SLIM Paper)
\end{itemize}

\end{frame}


\section{Correlated Data}
\begin{frame}{Correlated Data}
\textbf{Data}
\begin{itemize}
    \item $x_1,..., x_3 \sim U(-1,1), cor(x_1,x_2) = \rho_{12} \in \{0.1, 0.5, 0.9\}$ 
    \item $ f_{ls}(x) = x_1 + 4   x_2 + 3   x_2   x_3 $
    \item $\epsilon \sim N(0, 0.1 sd(f_{ls}(x))$
    \item $y = f_{ls}(x) + \epsilon$
\end{itemize}

\textbf{Question:} \\
Are there differences between the algorithms when correlated data are included? How often is $x_1$ incorrectly chosen as a splitting variable?
    
\end{frame}

\begin{frame}{Correlated Data}
\begin{table}

\caption{Mean simulation results, in particular, the relative frequency that x1 was chosen as a splitting variable by an MBT algorithm, on 500 simulation runs as stand alone model on scenario Correlated Data with n = 1000, alpha = 0.001, impr = 0.01}
\centering
\begin{tabular}[t]{l|r|r|r|r|r}
\hline
MBT & rho & frequency of x1  & number of leaf nodes & R2 train & R2 test\\
\hline
SLIM & 0.1 & 0.096 & 10.140 & 0.9860 & 0.9832\\
\hline
GUIDE & 0.1 & 0.058 & 9.950 & 0.9859 & 0.9832\\
\hline
MOB & 0.1 & 0.000 & 9.386 & 0.9898 & 0.9876\\
\hline
CTree & 0.1 & 0.000 & 11.294 & 0.9901 & 0.9881\\
\hline
SLIM & 0.5 & 0.144 & 9.892 & 0.9865 & 0.9839\\
\hline
GUIDE & 0.5 & 0.126 & 9.654 & 0.9864 & 0.9840\\
\hline
MOB & 0.5 & 0.000 & 9.034 & 0.9899 & 0.9878\\
\hline
CTree & 0.5 & 0.000 & 10.682 & 0.9900 & 0.9882\\
\hline
SLIM & 0.9 & 0.322 & 9.826 & 0.9866 & 0.9842\\
\hline
GUIDE & 0.9 & 0.384 & 9.784 & 0.9870 & 0.9848\\
\hline
MOB & 0.9 & 0.058 & 8.690 & 0.9899 & 0.9879\\
\hline
CTree & 0.9 & 0.036 & 10.216 & 0.9900 & 0.9883\\
\hline
\end{tabular}
\end{table}    
\end{frame}


\begin{frame}{Bibliography}
    \bibliography{bibliography}
    \bibliographystyle{dcu}

\end{frame}
\end{document}