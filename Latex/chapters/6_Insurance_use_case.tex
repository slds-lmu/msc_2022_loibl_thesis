In the following, SLIM is used in various configurations as a surrogate for modelling the benefit present values of two fictitious insurance tariffs from the TRAIL.X (TRustworthy Artificial Intelligence in Life Insurance) research project \citep{msginsurit.16.03.2023}. The results are interpreted and the fidelity is compared with the MBT algorithms GUIDE, MOB and CTree.

\subsection{Data set K2204}
The data set K2204 contains data for a (fictitious) endowment insurance tariff. With this tariff, a single benefit is paid both in the event of survival and death of the policyholder. The data set includes the features sex (1 = male, 0 = female), age and duration and the two targets benefit present value (BPV) and premium present value (PPV). The targets were modelled using two different black box models.  
In the following, only the BPV is considered. The results for the PBV are very similar (interpreted the other way round) and can be found in the appendix.
Since the data set with 5994 observations is rather small, all observations were used for training. For this data set therefore only training performance of the surrogate models is considered.
A special characteristic of K2204 is a correlation between the features age and duration, as can be seen in Figure \ref{fig:ins_corr_age_duration}. When interpreting a MBT for this data set, it must therefore be taken into account that a split with regard to one of the features can have an influence on the value range of the other feature.

\begin{figure}[!htb]
    \centering    
    \includegraphics[width=5cm]{Figures/insurance_use_case/k2204_BPV/corr_age_duration.png}
    \caption{Features age and duration in the K2204 data set}
    \label{fig:ins_corr_age_duration}
\end{figure}


\subsubsection{Shallow MBTs with linear models}
In a first step, SLIM was fitted as surrogate to the black box predictions of BPV (BPV\_pred) with linear regression models in the nodes. The maximum depth was set to 3 and an improvement in the objective ($impr$) of at least $0.1$ of the previous improvement was set as prepruning parameter.
 The resulting tree is shown in Figure \ref{fig:ins_slim_lm_tree}.

 \begin{figure}[!htb]
     \centering     
     \includegraphics[width = 14cm]{Figures/insurance_use_case/k2204_BPV/slim_lm_tree.png}
     \caption{SLIM tree for K2204 with linear models}
     \label{fig:ins_slim_lm_tree}
 \end{figure}

Basic observations across all subregions are:
\begin{itemize}
    \item Gender male has a positive effect on BPV\_pred
    \item age has a positive effect on BPV\_pred
    \item duration has a negative effect on BPV\_pred
\end{itemize}

The strength of the effects, however, differs in the different subregions found by SLIM.
The five leafnodes can be roughly divided into two regions with similar effects:
\begin{itemize}
    \item Region 1 (Nodes 2,8): High duration ($30$) or high age ($>48$) and medium duration (between $13$ and $30$)
    \item Region 2 (Nodes 5,6,7): Low - medium duration with low age or high age with low duration ($\leq 12$)
\end{itemize}

In Region 1 sex male and age seem to have a higher positive effect on  BPV\_pred than in region 2. The negative effect of duration, on the other hand, is smaller in region 1. This indicates a non-linearity of duration.

If SLIM is fitted as a standalone model instead of a surrogate model in the same configuration, the differences in the split points are very small. This indicates that the black box model captures the underlying relationships very well. The corresponding tree is shown in the appendix in Figure \ref{fig:app_ins_slim_lm_standalone_tree}.

In the following, the fidelity of the different MBT with algorithms with linear models is compared. For this purpose, all four algorithms were fitted with a maximum depth of 3. For SLIM and GUIDE, $impr$ is set to $0.05$ and for MOB and CTree $alpha$ is set to $0.05$. Furthermore, a minimum nodesize of 200 observations is required.
The MBTs are compared with a baseline model, which is a linear regression model on the entire feature space. In addition to the $R^2$ and the MSE, the mean absolute error (MAE) and the maximum absolute error (max AE) are included as measures of fidelity. The max AE is particularly important here, as it is strictly regulated in order not to discriminate against any individual. 
The results are listed in table \ref{tab:ins_k2204_lm_surrogates_perf}. It shows that all MBTs achieve considerable improvement over the baseline model.

\begin{table}[!htb]

\caption{Fidelity of K2204 linear baseline model and linear MBTs}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r|r|r}
\hline
  & $R^2$ & MSE & MAE & max AE & n leaves\\
\hline
linear baseline model & 0.985101 & 0.000201 & 0.011393 & 0.064709 & 1\\
\hline
SLIM & 0.999233 & 0.000010 & 0.002272 & 0.020526 & 8\\
GUIDE & 0.999276 & 0.000010 & 0.002142 & 0.020526 & 8\\
MOB & 0.998527 & 0.000020 & 0.003149 & 0.024504 & 8\\
CTree & 0.995091 & 0.000066 & 0.005740 & 0.042931 & 8\\
\hline
\end{tabular}
\label{tab:ins_k2204_lm_surrogates_perf}
\end{table}

GUIDE achieves the best performance slightly ahead of SLIM. CTree obtains the worst performance.
Since all algorithms generate MBTs with the same number of leafnodes, the difference in performance must be explained by different split features or points.
Table \ref{tab:ins_k2204_lm_surrogates_share} lists the share of observations that were split with respect to the different features.

\begin{table}[!htb]

\caption{Share of observations split by the different features K2204 linear MBTs}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r}
\hline
& age & duration & sex\\
\hline
SLIM & 0.28 & 0.67 & 0.05\\
GUIDE & 0.28 & 0.72 & 0.00\\
MOB & 0.10 & 0.77 & 0.13\\
CTree & 0.00 & 0.96 & 0.04\\
\hline
\end{tabular}
\label{tab:ins_k2204_lm_surrogates_share}
\end{table}

It is noticeable that SLIM and GUIDE split by age more often than the other two algorithms.

\subsubsection{MBTs with B-spline models}

In order to better capture non-linearities and thus reduce the risk of splitting with respect to non-linearities instead of interactions, all MBT algorithms are fitted with B-spline transformed feature age and duration as surrogate models. 
Two different maximal depths are used, 3 for interpretable shallow trees and 6 for deep trees with higher fidelity. The settings for $alpha$, $impr$ and minimum nodesize remain the same as for the MBTs with linear models.  Again, a baseline model is fitted, in this case a regression model with the feature sex and B-spline transformed features age and duration on the entire feature space. 

Figure \ref{fig:ins_k2204_fit} plots the prediction of the baseline B-spline model and the two B-spline SLIM surrogates against BPV\_pred to visualise performance improvement. This shows a considerable improvement from the baseline model to the shallow tree. For the deep tree, the observations seem to be even somewhat closer to the identity line. 

\begin{figure}[!htb]
    \centering    
    \includegraphics[width = 14cm]{Figures/insurance_use_case/k2204_BPV/fit.png}
    \caption{B-spline surrogate predictions vs. BPV\_pred for K2204}
    \label{fig:ins_k2204_fit}
\end{figure}

The fidelity results for all B-spline surrogates are listed in table \ref{tab:ins_k2204_bsplines_surrogates_perf} .

\begin{table}

\caption{Fidelity of K2204 B-spline baseline model and  B-spline MBTs}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r|r|r}
\hline
  & $R^2$ & MSE & MAE & max AE & n leaves\\
\hline
B-spline baseline model & 0.9943311 & 7.63e-05 & 0.0067811 & 0.0378568 & 1\\
\hline
SLIM shallow & 0.9994176 & 7.80e-06 & 0.0018244 & 0.0167730 & 8\\
GUIDE shallow & 0.9993900 & 8.20e-06 & 0.0019011 & 0.0165545 & 8\\
MOB shallow & 0.9992115 & 1.06e-05 & 0.0022236 & 0.0182034 & 8\\
CTree shallow & 0.9990918 & 1.22e-05 & 0.0024194 & 0.0183906 & 8\\
\hline
SLIM deep & 0.9997514 & 3.30e-06 & 0.0010766 & 0.0126778 & 21\\
GUIDE deep & 0.9997301 & 3.60e-06 & 0.0011730 & 0.0116453 & 20\\
MOB deep & 0.9996858 & 4.20e-06 & 0.0013448 & 0.0119785 & 21\\
CTree deep & 0.9997091 & 3.90e-06 & 0.0012936 & 0.0123686 & 20\\
\hline
\end{tabular}
\label{tab:ins_k2204_bsplines_surrogates_perf}
\end{table}


The improvement of the shallow MBTs over the baseline model is large, but not as substantial as in the trees with linear models without B-spline transformations. This is probably due to the fact that the splits in the MBTs with linear models also handled non-linearities that could not be adjusted in the linear baseline model. In the baseline model with B-spline transformations, on the other hand, the non-linearities are already taken into account and the splits then actually capture primarily the interactions, which is what is desired. 
The deeper splitting improves the performance of all MBTs considerably. The MAE of the deep trees, for example, is only 52\%-61\% of the MAE of the shallow trees. CTree achieves the greatest improvement and obtains better fidelity in the deep trees than MOB (except for max AE). The better performance of all MBTs, however, comes at the cost of interpretability. Additionally, there is an increased risk of overfitting.


Table \ref{tab:ins_k2204_bsplines_surrogates_share}  shows the proportions of observations that were split according to the different features. 


\begin{table}[!htb]
\caption{Share of observations split by the different features K2204 B-spline MBTs}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r}
\hline
  & age & duration & sex\\
\hline
SLIM shallow & 0.38 & 0.62 & 0.00\\
GUIDE shallow & 0.30 & 0.70 & 0.00\\
MOB shallow & 0.08 & 0.84 & 0.08\\
CTree shallow & 0.23 & 0.71 & 0.07\\
\hline
SLIM deep & 0.35 & 0.60 & 0.04\\
GUIDE deep & 0.20 & 0.78 & 0.02\\
MOB deep & 0.08 & 0.76 & 0.16\\
CTree deep & 0.20 & 0.67 & 0.13\\
\hline
\end{tabular}
\label{tab:ins_k2204_bsplines_surrogates_share}
\end{table}

For SLIM, GUIDE and MOB the share results of the shallow trees are similar to the MBTs with linear models. Shallow CTree, on the other hand, selects age in $23\%$ of split observations as splitting variable, whereas it was not used at all for splitting in CTree with linear models. It performs the worst in terms of fidelity in this case as well, but not as considerable as in the previous setting.
With the deep trees, the values for share and also the fidelity values of the different MBTs move closer together.



For the interpretation, the shallow SLIM B-spline tree is analysed in more detail.

\begin{figure}[!htb]
    \centering   
    \includegraphics[width = 16cm]{Figures/insurance_use_case/k2204_BPV/slim_bsplines_small_tree.png}
         \caption{SLIM tree for K2204 with B-spline models}
     \label{fig:ins_slim_bsplines_tree}
\end{figure}

In order to investigate the effects of the splits on the feature effects more closely, the splits with regard to duration and age are analysed separately.
The nodes 1,5,13 and 14 together comprise the entire feature space, whereby the sub-regions are determined by splits with regard to the feature duration.
Figure \ref{fig:ins_k2204_effects_duration} shows the input-output relation (feature effects) of the features estimated in the B-spline models in the different nodes. Note that the curves are centred.

\begin{figure}[!htb]
    \centering
    \includegraphics[width = 16cm]{Figures/insurance_use_case/k2204_BPV/effects_duration.png}
    \caption{Input-output relation of features in nodes split by duration for SLIM tree with B-splines and depth 3}
    \label{fig:ins_k2204_effects_duration}
\end{figure}

As with SLIM with linear models, it can be seen that the positive effect of sex male seems to increase with increasing duration. The same applies to age. The seemingly negative effect of age at low duration and high age is probably due to extrapolation, as there are only
few observations in this area, which is shown in Figure \ref{fig:ins_k2204_hist_age}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width = 12cm]{Figures/insurance_use_case/k2204_BPV/hist_age.png}
    \caption{Frequency of observations with respect to feature age}
    \label{fig:ins_k2204_hist_age}
\end{figure}

With the feature duration, it can be seen that the negative effect seems to decrease with increasing duration, which is again just a non-linearity.

To investigate the effect of splits with respect to feature age, on the one hand nodes 4,7 and 8 are compared, which cover the featurespace for duration $\leq 25$, and on the other hand nodes 11 and 12, which cover the featurespace for $25 > $duration $<= 40$. In the Figures \ref{fig:ins_k2204_effects_age_low_duration} and \ref{fig:ins_k2204_effects_age_medium_duration} the corresponding input-output relations of the features are shown.

\begin{figure}[!htb]
    \centering    
    \includegraphics[width = 16cm]{Figures/insurance_use_case/k2204_BPV/effects_age_low_duration.png}
    \caption{Input-output relation of features in nodes with duration $\leq 25$ split by age for SLIM tree with B-splines and depth 3}
    \label{fig:ins_k2204_effects_age_low_duration}
\end{figure}

\begin{figure}[!htb]
    \centering    
    \includegraphics[width = 16cm]{Figures/insurance_use_case/k2204_BPV/effects_age_medium_duration.png}
    \caption{Input-output relation of features in nodes with $25 > $duration $<= 40$ split by age for SLIM tree with B-splines and depth 3}
    \label{fig:ins_k2204_effects_age_medium_duration}
\end{figure}

Again, the interpretation is consistent with the results from SLIM with linear models. The positive effect of sex and age is increased by increasing age, while the negative effect of duration is reduced. The slightly negative effect of age at high age and low duration should again be viewed with caution and is probably due to the poor data situation in this area.


Finally, a deep SLIM tree with B-spline models is used as a standalone model for BPV and its accuracy is compared to the accuracy of the black box model. The result is shown in Table \ref{tab:ins_k2204_standalone_slim}.
The accuracy of SLIM is worse than that of the black box model for all evaluation measures. However, the difference is most apparent for the max AE. While the max AE is explicitly minimised in the black box model, the MSE is minimised with SLIM. In general, a different loss function would also be possible with SLIM. In this case, either the max AE could be minimised only in the split selection, or also in the modelling in the nodes. When optimising the max AE in the split selection, it must be noted that the algorithm is principally designed for additive loss functions. In order to compare the joint performance of the child models with that of the parent model, the maximum should probably be used instead. 
However, it is questionable whether the data would be split according to interactions in this case, especially if the models were nevertheless fitted using least squared regression.

\begin{table}[!htb]

\caption{Accuracy of standalone B-spline SLIM MBTs and of the black box model K2204}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r|r}
\hline
  & $R^2$ & MSE & MAE & max AE \\
\hline
SLIM & 0.9997757 & 3.1e-06 & 0.0010172 & 0.0118951\\
Blackbox model & 0.9998316 & 2.3e-06 & 0.0009441 & 0.0047668\\
\hline
\end{tabular}
\label{tab:ins_k2204_standalone_slim}
\end{table}








\subsection{Data set R1\_08}

The data set R1\_08 contains the data of an annuity insurance tariff. Instead of a single benefit in the endowment case, a lifelong annuity is paid out.
R1\_08 includes, in addition to sex, age and duration, the features birth\_year, payment\_period, in\_year\_payments\_exkasso (categorical with 4 levels), guarantee\_period and increment\_factor.
The value range of the features age and duration is limited to a range in which no correlation exists ($25 \leq$ age $\leq 35$ and $30 \leq$ duration $\leq 40$).
Here, as well, the BPV or BPV\_pred is analysed as target variable. Here, as well, the BPV and BPV\_pred predicted by a black box model are analysed as target variables.
For the application of the MBTs, subsets of the training and test datasets including BPV and BPV\_pred are drawn, each with 100000 observations.

In order to model non-linearities in the nodes, MBTs with B-spline models are used. As with K2204, trees with two different depths are evaluated, shallow trees with a maximum depth of 3 and deep trees with a maximum depth of 7. $impr$ and $alpha$ are set to 0.05 and a minimum nodesize of 500 observations is required.

For the interpretation of the splits and models, the shallow SLIM tree is examined in more detail. Its structure is shown in Figure \ref{fig:ins_k108_slim_bsplines_small_tree}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width = 16cm]{Figures/insurance_use_case/k1_08_BPV/slim_bsplines_small_tree.png}
    \caption{Shallow SLIM tree for K1\_08 with B-spline models}
    \label{fig:ins_k108_slim_bsplines_small_tree}
\end{figure}

If the tree is fitted on the test data instead of the training data, exactly the same splits result. The same applies if the tree is used as a standalone model for BPV instead of a surrogate model. This indicates that the black box model replicates the true data and relationships well.
It is noticeable that the featurespace in the first splits is only divided with regard to increment\_factor. The effects of these splits on the other features are shown in Figure \ref{fig:ins_k108_effects_increment}.

\begin{figure}[!htb]
    \centering    
    \includegraphics[width=16cm]{Figures/insurance_use_case/k1_08_BPV/effects_increment_factor.png}
    \caption{Input-output relation of features in nodes split by increment\_factor for SLIM tree with B-splines and depth 3}
    \label{fig:ins_k108_effects_increment}
\end{figure}

The effects of the features payment\_period and guarantee\_period are not shown because they are very small and therefore not visible on the scale at all.
The interaction with increment\_factor is clearly visible in all the features shown. For all features, an increasing increment\_factor increases the feature effects.
The consequences of the splits with respect to duration are shown in Figure \ref{fig:ins_k108_effects_duration}. It shows that across all shown features a higher duration weakens the feature main effects.

\begin{figure}[!htb]
    \centering 
    \includegraphics[width=16cm]{Figures/insurance_use_case/k1_08_BPV/effects_duration.png}
    \caption{Input-output relation of features in nodes split by duration for SLIM tree with B-splines and depth 3 (nodes 11-14)}
    \label{fig:ins_k108_effects_duration}
\end{figure}


Since increment\_factor interacts with so many features, the splits are very effective here and bring a great improvement in performance. Table \ref{tab:ins_k108_share} shows the share of the splits by the different features. From this it can be seen that MOB and CTree split shallow MBTs considerably less by increment\_factor than SLIM and GUIDE. At the same time, their performance is behind that of SLIM and GUIDE, as can be seen in Table \ref{tab:ins_k108_bsplines_surrogates_perf}. SLIM achieves the best performance.





By using deep trees, the fidelity increases and the results of the different algorithms move closer together. The values for share also get closer. Overall, the differences between the different algorithms are therefore less pronounced with the deep trees than with the shallow trees. Although the deep trees achieve a high training performance, an interpretation is hardly possible with this high number of leaf nodes. In addition, the test performance differs more strongly from the training performance than with the shallow trees, which is a sign of overfitting.



\begin{table}[!htb]

\caption{fidelity of K1\_08 B-spline baseline model and  B-spline MBTs K2204}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r|r|r|r|r|r|r}
\hline
& \multicolumn{4}{|c|}{train} & \multicolumn{4}{|c|}{test} & \\
hline
 & $R^2$ & MSE & MAE & max AE & $R^2$ & MSE & MAE & max AE & n leaves\\
\hline

B-spline & 0.927748 & 3.534102 & 1.291762 & 16.412655 & 0.927267 & 3.558816 & 1.295778 & 16.413200 & 1\\
\hline
SLIM shallow & 0.997432 & 0.125606 & 0.235344 & 4.296943 & 0.997397 & 0.127386 & 0.236761 & 4.299219 & 8\\
GUIDE shallow & 0.996540 & 0.169233 & 0.262321 & 5.006522 & 0.996496 & 0.171433 & 0.263770 & 5.003334 & 8\\
MOB shallow & 0.994944 & 0.247289 & 0.324474 & 5.236252 & 0.994942 & 0.247489 & 0.324895 & 5.336406 & 8\\
CTree shallow & 0.993049 & 0.340023 & 0.401982 & 5.236252 & 0.993055 & 0.339838 & 0.401632 & 5.336406 & 8\\
\hline
SLIM deep & 0.999882 & 0.005794 & 0.043939 & 1.079069 & 0.999870 & 0.006350 & 0.045885 & 1.126732 & 105\\
GUIDE deep & 0.999844 & 0.007652 & 0.052102 & 1.079069 & 0.999832 & 0.008219 & 0.054046 & 1.126732 & 95\\
MOB deep & 0.999861 & 0.006823 & 0.047428 & 1.079069 & 0.999848 & 0.007460 & 0.049459 & 1.126732 & 108\\
CTree deep & 0.999839 & 0.007851 & 0.058806 & 1.079069 & 0.999825 & 0.008539 & 0.061363 & 1.126732 & 106\\
\hline
\end{tabular}
\label{tab:ins_k108_bsplines_surrogates_perf}
\end{table}




\begin{table}[!htb]
\caption{Share of observations split by the different features K1\_08 B-spline MBTs}
\centering \scriptsize
\begin{tabular}[t]{l|r|r|r|r|r}
\hline
  & sex & age & duration & birth\_year & increment\\
\hline
SLIM shallow & 0.00 & 0.00 & 0.12 & 0.00  & 0.88\\
GUIDE shallow & 0.00 & 0.12 & 0.00 & 0.00  & 0.88\\
MOB shallow & 0.00 & 0.12 & 0.33 & 0.00  & 0.54\\
CTree shallow & 0.00 & 0.33 & 0.33 & 0.00  & 0.33\\
\hline
SLIM deep & 0.10 & 0.08 & 0.24 & 0.05 & 0.54\\
GUIDE deep & 0.06 & 0.10 & 0.22 & 0.05 & 0.56\\
MOB deep & 0.11 & 0.15 & 0.20 & 0.03 & 0.52\\
CTree deep & 0.00 & 0.17 & 0.29 & 0.05 & 0.49\\
\hline
\end{tabular}
\label{tab:ins_k108_share}
\end{table}

The feature payment\_period, in\_year\_payments\_exkasso and guarantee\_period are never chosen as splitting variables and are therfore not listed in the table.


As for K2204 two SLIM trees with B-spline models are fitted as  standalone models for BPV and their accuracy is compared with the black box model. The result is shown in Table \ref{tab:ins_k108_standalone_slim}. For this data set, too, the deviations are most considerable for the max ae





\begin{table}[!htb]

\caption{Accuracy of standalone B-spline SLIM MBTs and of the black box model K1\_08}
\centering \scriptsize  
\begin{tabular}[t]{l|r|r|r|r|r|r|r|r}
\hline
 & \multicolumn{4}{|c|}{train} & \multicolumn{4}{|c}{test} \\
\hline
 & $R^2$ & MSE & MAE & max AE & $R^2$ & MSE & MAE & max AE \\
\hline
SLIM shallow & 0.9974321 & 0.1256075 & 0.2353447 & 4.3046812 & 0.9973966 & 0.1273854 & 0.2367417 & 4.3074899\\
SLIM deep & 0.9998814 & 0.0057987 & 0.0439357 & 1.0862638 & 0.9998702 & 0.0063532 & 0.0458758 & 1.1344576\\
Blackbox & 1.0000000 & 0.0000023 & 0.0011006 & 0.0096827 & 1.0000000 & 0.0000023 & 0.0010968 & 0.0099144\\
\hline
\end{tabular}
\label{tab:ins_k108_standalone_slim}
\end{table}