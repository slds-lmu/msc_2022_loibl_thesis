Various machine learning algorithms achieve outstanding predictive performance nowadays. However, most of them are complex black box models that, unlike traditional statistical methods such as linear regression, are not intrinsically interpretable \citep{Hu.2020}.
Especially in highly regulated industries such as insurance, this is a problem \citep{Henckaerts.2022}.
In order to maintain the good performance of complex black box models but still achieve a certain degree of interpretability, there exist different methods with which models can be interpreted post-hoc. 


One option are so called surrogate models. The idea is to approximate the predictions of black box models by intrinsically interpretable models \citep{Molnar.2019}.
But in order for a surrogate model's explanations to be trusted, it must itself perform well in approximating the black box predictions.
There are basically two approaches for generating surrogate models: global surrogate models, which cover the entire feature space and can be interpreted globally, but often do not perform that well, or local surrogate models, which only explain individual observations.  The focus of this work is on a mixture of the two approaches, which are called subregional surrogate models here. 
The idea is to find subregions in the feature space in which intrinsically interpretable models can be fitted.


Model-based tree (MBT) algorithms are a promising class to generate such subregional models. 
The concept of MBTs is based on classical regression trees like CART \citep{Breiman.1984} but a MBT contains models instead of constant values in the subregions (called nodes or leaf nodes).
It is hence a combination of decision rules and models. If intrinsically interpretable models are chosen for the models, a principally interpretable MBT is derived. The degree of interpretability and performance, though, depends on the complexity of the decision rules (i.e. depth of the tree or number of leaf nodes) and of the models.
In order to enable a good interpretability of the models in the leaf nodes, this thesis sets the constraint that only main effect models are fitted in the nodes. 
In the ideal case, interactions should then be handled by  splits, so that the models in the leaf nodes are free from interaction effects.
To ensure that the splits are actually due to interactions and not to nonlinearities, it is necessary that potentially nonlinear main effects are modelled appropriately.
Although in some cases linear modelling of the main effects is sufficient, it should also be possible to fit more complex models, such as (penalized) polynomial models or generalised additive models (GAM).
The goal is thus an additive decomposition of a black box function by combining decision rules and additive main effect models.  In other words
subregions in the feature space should be found, so that the global black box model can be replaced by subregional main effect models.


In my research, I found four different algorithms that can generate MBTs. 
The most recent approach Surrogate Locally-Interpretable Models (SLIM) by \cite{Hu.2020} allows a high flexibility in the choice of model classes in the leaf nodes. SLIM uses an exhaustive search to find the best split point through all possible splitting variables. 
In this thesis SLIM is contrasted with three common algorithms for creating MBTs: Model-based recursive Partitioning (MOB) \citep{Zeileis.2008}, Conditional Inference Trees (CTree) \citep{Hothorn.2006} and Regression tress with unbiased variable selection and interaction detection (GUIDE) \citep{Loh.2002}. These algorithms differ from SLIM mainly in that the search for the best split point is a two-step process. First, the best split variable is selected by a hypothesis test, which differs between the three algorithms. Then, in a second step, the best split point for this variable is searched. Since certain prerequisites must be fulfilled for the hypothesis tests, the choice of model classes for these algorithms is limited to some extent. 

The comparison of the four algorithms is made with the condition that main effect only models are fitted in the nodes and all features are included in the search for the splitting variable. First, it is examined how the algorithms differ in terms of selection bias. Afterwards, they are compared with regard to their performance, interpretability and stability, as tree algorithms often suffer from poor stability \citep{Fokkema.2020}. In the subsequent application to data sets from the area of life insurance, their suitability as surrogate models is examined.

The main results of this thesis are that SLIM and GUIDE are particularly successful in terms of performance, interpretability and stability when subgroup specific maineffects are present in the data. Smooth interactions are partially better modelled by MOB and CTree. In general for data with smooth interactions all four algorithms produce models with a large number of subregions when high performance is required. The MBTs are then difficult to interpret and less suitable as surrogate models. Furthermore, when applied to the insurance data, it is noticeable that the deeper the MBTs are, the more similar the performance of the different algorithms becomes.

The thesis is structured as follows:
In chapter \ref{related}, an overview of surrogate models is given and MBTs are placed in this setting. Thereafter, the four MBT algorithms are described in chapter \ref{background}. Chapter \ref{selection} examines the extent to which the algorithms suffer from selection bias. In chapter \ref{simulation}, different simulation scenarios are used to examine how the algorithms differ in terms of performance, interpretability and stability. In addition, the interpretability and performance of the SLIM algorithm are examined when the complexity of the leaf node models is varied. Finally, in chapter \ref{usecase} the algorithms are used as surrogate models for the modelling of insurance data and different SLIM models are used for interpretation. 

